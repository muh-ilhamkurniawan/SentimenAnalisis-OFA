{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from timeout_decorator import timeout, TimeoutError\n",
    "import multiprocessing\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca data dari file CSV\n",
    "df = pd.read_csv('ML2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat peta untuk encoding\n",
    "polarity_encode = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "# Mengonversi label 'polarity' ke nilai numerik\n",
    "df['polarity_encoded'] = df['polarity'].map(polarity_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan data menjadi data latih dan uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_teks'], df['polarity_encoded'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisasi teks\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequence agar memiliki panjang yang sama\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=100, truncating='post', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=100, truncating='post', padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userName</th>\n",
       "      <th>score</th>\n",
       "      <th>at</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_teks</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Kayna Adiva</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-31T17:01:24.000</td>\n",
       "      <td>Saya rank legend 5 malah terus bertemu musuh y...</td>\n",
       "      <td>peringkat,legend,temu,musuh,legend,kalah,tim,m...</td>\n",
       "      <td>-6</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>kasfy nisya</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-11-03T10:00:36.000</td>\n",
       "      <td>Bagus, cuman kadang dlm pertandingan ga seimba...</td>\n",
       "      <td>bagus,cuman,kadang,dlm,tanding,tidak,imbang,so...</td>\n",
       "      <td>-15</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sun thin Then</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-29T15:10:42.000</td>\n",
       "      <td>Gamenya sih udah bagus bgt, grafiknya mantap, ...</td>\n",
       "      <td>game,sih,sudah,bagus,banget,grafik,mantap,back...</td>\n",
       "      <td>12</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Star space</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-29T11:50:33.000</td>\n",
       "      <td>Game nya sudah bagus tetapi ada beberapa masal...</td>\n",
       "      <td>game,bagus,resah,dark,sistem,sudah,hapus,tu,na...</td>\n",
       "      <td>-18</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abdul Ghani Rossyidi</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-29T20:25:49.000</td>\n",
       "      <td>Untuk event2 sdah oke lah. Tapi tolong priorit...</td>\n",
       "      <td>event,sdah,oke,tolong,prioritas,nyaman,main,ja...</td>\n",
       "      <td>-7</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>Ardi Putra</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-10T22:50:04.000</td>\n",
       "      <td>Keluh kesah banget nih hari ini, Pliss lah dar...</td>\n",
       "      <td>keluh,kesah,banget,ini,tolong,moonton,tolong,k...</td>\n",
       "      <td>-21</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>Gilang Gilang</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-27T06:10:55.000</td>\n",
       "      <td>Aneh padahal penyimpanan masih banyak masa lag...</td>\n",
       "      <td>aneh,simpan,lag,langsung,relog,gameplay,ku,rus...</td>\n",
       "      <td>-7</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>Ktek alas</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-03T09:08:58.000</td>\n",
       "      <td>Untuk Moonton tolong perbaiki masalah jaringan...</td>\n",
       "      <td>moonton,tolong,baik,jaringan,bug,jaringan,alam...</td>\n",
       "      <td>-2</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>Umrotull 029</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-27T18:10:49.000</td>\n",
       "      <td>Kenapa ya sekarang kalau update lama banget pd...</td>\n",
       "      <td>iya,terbaru,banget,padahal,pakai,wifi,pakai,da...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>And ADR</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-04T23:39:03.000</td>\n",
       "      <td>Kenapa lg ini game. Kalian juga tahu sendiri l...</td>\n",
       "      <td>lagi,game,lahbanyaknya,matchmaking,game,tim,do...</td>\n",
       "      <td>12</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0              userName  score                       at  \\\n",
       "0            0           Kayna Adiva      1  2023-10-31T17:01:24.000   \n",
       "1            1           kasfy nisya      4  2023-11-03T10:00:36.000   \n",
       "2            2         Sun thin Then      1  2023-10-29T15:10:42.000   \n",
       "3            3            Star space      1  2023-10-29T11:50:33.000   \n",
       "4            4  Abdul Ghani Rossyidi      3  2023-10-29T20:25:49.000   \n",
       "..         ...                   ...    ...                      ...   \n",
       "95          95            Ardi Putra      2  2023-10-10T22:50:04.000   \n",
       "96          96         Gilang Gilang      1  2023-09-27T06:10:55.000   \n",
       "97          97             Ktek alas      1  2023-10-03T09:08:58.000   \n",
       "98          98          Umrotull 029      1  2023-09-27T18:10:49.000   \n",
       "99          99               And ADR      1  2023-10-04T23:39:03.000   \n",
       "\n",
       "                                              content  \\\n",
       "0   Saya rank legend 5 malah terus bertemu musuh y...   \n",
       "1   Bagus, cuman kadang dlm pertandingan ga seimba...   \n",
       "2   Gamenya sih udah bagus bgt, grafiknya mantap, ...   \n",
       "3   Game nya sudah bagus tetapi ada beberapa masal...   \n",
       "4   Untuk event2 sdah oke lah. Tapi tolong priorit...   \n",
       "..                                                ...   \n",
       "95  Keluh kesah banget nih hari ini, Pliss lah dar...   \n",
       "96  Aneh padahal penyimpanan masih banyak masa lag...   \n",
       "97  Untuk Moonton tolong perbaiki masalah jaringan...   \n",
       "98  Kenapa ya sekarang kalau update lama banget pd...   \n",
       "99  Kenapa lg ini game. Kalian juga tahu sendiri l...   \n",
       "\n",
       "                                           clean_teks  polarity_score  \\\n",
       "0   peringkat,legend,temu,musuh,legend,kalah,tim,m...              -6   \n",
       "1   bagus,cuman,kadang,dlm,tanding,tidak,imbang,so...             -15   \n",
       "2   game,sih,sudah,bagus,banget,grafik,mantap,back...              12   \n",
       "3   game,bagus,resah,dark,sistem,sudah,hapus,tu,na...             -18   \n",
       "4   event,sdah,oke,tolong,prioritas,nyaman,main,ja...              -7   \n",
       "..                                                ...             ...   \n",
       "95  keluh,kesah,banget,ini,tolong,moonton,tolong,k...             -21   \n",
       "96  aneh,simpan,lag,langsung,relog,gameplay,ku,rus...              -7   \n",
       "97  moonton,tolong,baik,jaringan,bug,jaringan,alam...              -2   \n",
       "98  iya,terbaru,banget,padahal,pakai,wifi,pakai,da...               0   \n",
       "99  lagi,game,lahbanyaknya,matchmaking,game,tim,do...              12   \n",
       "\n",
       "    polarity  polarity_encoded  \n",
       "0   negative                 0  \n",
       "1   negative                 0  \n",
       "2   positive                 2  \n",
       "3   negative                 0  \n",
       "4   negative                 0  \n",
       "..       ...               ...  \n",
       "95  negative                 0  \n",
       "96  negative                 0  \n",
       "97  negative                 0  \n",
       "98   neutral                 1  \n",
       "99  positive                 2  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi model dengan nilai hyperparameter default\n",
    "def create_model(embed_dim=16, hidden_unit=16, dropout_rate=0.2, optimizers=Adam, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=embed_dim, input_length=100))\n",
    "    model.add(LSTM(units=hidden_unit, activation='tanh'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizers(lr=learning_rate), metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ILHAM\\AppData\\Local\\Temp\\ipykernel_18804\\2195023938.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model,\n"
     ]
    }
   ],
   "source": [
    "# Model pembungkus dengan nilai hyperparameter terbaik\n",
    "model = KerasClassifier(build_fn=create_model,\n",
    "                        dropout_rate=0.2,\n",
    "                        embed_dim=32,\n",
    "                        hidden_unit=16,\n",
    "                        optimizers=RMSprop,\n",
    "                        learning_rate=0.001,\n",
    "                        epochs=10,\n",
    "                        batch_size=128,\n",
    "                        validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model dengan GridSearchCV untuk mengetahui hyperparameter terbaik untuk model\n",
    "param_grid = dict(embed_dim=[32, 64],\n",
    "                  hidden_unit=[16, 32, 64],\n",
    "                  dropout_rate=[0.2],\n",
    "                  optimizers=[Adam, RMSprop],\n",
    "                  learning_rate=[0.01, 0.001, 0.0001],\n",
    "                  epochs=[10, 25, 50, 100],\n",
    "                  batch_size=[128, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6969 - accuracy: 0.1702 - val_loss: 0.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6914 - accuracy: 0.0426 - val_loss: 0.6877 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7015 - accuracy: 0.1277 - val_loss: 0.6793 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6942 - accuracy: 0.0213 - val_loss: 0.6837 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6964 - accuracy: 0.0426 - val_loss: 0.6880 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6866 - accuracy: 0.1915 - val_loss: 0.6860 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6955 - accuracy: 0.1702 - val_loss: 0.6822 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6978 - accuracy: 0.0638 - val_loss: 0.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6862 - accuracy: 0.0426 - val_loss: 0.6764 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6774 - accuracy: 0.0426 - val_loss: 0.6731 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6929 - accuracy: 0.0741\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6935 - accuracy: 0.7021 - val_loss: 0.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6929 - accuracy: 0.0638 - val_loss: 0.6776 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6906 - accuracy: 0.0638 - val_loss: 0.6745 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6928 - accuracy: 0.0638 - val_loss: 0.6731 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6909 - accuracy: 0.0638 - val_loss: 0.6706 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6877 - accuracy: 0.0638 - val_loss: 0.6665 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6942 - accuracy: 0.0638 - val_loss: 0.6630 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6875 - accuracy: 0.0638 - val_loss: 0.6606 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6857 - accuracy: 0.0638 - val_loss: 0.6611 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6783 - accuracy: 0.0426 - val_loss: 0.6641 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6946 - accuracy: 0.0000e+00\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6953 - accuracy: 0.4792 - val_loss: 0.6888 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6923 - accuracy: 0.0417 - val_loss: 0.6915 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6958 - accuracy: 0.1875 - val_loss: 0.6915 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6898 - accuracy: 0.1875 - val_loss: 0.6949 - val_accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6910 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7010 - accuracy: 0.2292 - val_loss: 0.6921 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6885 - accuracy: 0.3125 - val_loss: 0.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6935 - accuracy: 0.2917 - val_loss: 0.6927 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7020 - accuracy: 0.3125 - val_loss: 0.6954 - val_accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6968 - accuracy: 0.5625 - val_loss: 0.6958 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6944 - accuracy: 0.6923\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.6924 - accuracy: 0.0213 - val_loss: 0.6368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7434 - accuracy: 0.0213 - val_loss: 0.7112 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7058 - accuracy: 0.6809 - val_loss: 0.6813 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6882 - accuracy: 0.0426 - val_loss: 0.6771 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6987 - accuracy: 0.0426 - val_loss: 0.6857 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6909 - accuracy: 0.1489 - val_loss: 0.6762 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6915 - accuracy: 0.1064 - val_loss: 0.6810 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7019 - accuracy: 0.1064 - val_loss: 0.6701 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6901 - accuracy: 0.0213 - val_loss: 0.6777 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6831 - accuracy: 0.0638 - val_loss: 0.6685 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6936 - accuracy: 0.0741\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6905 - accuracy: 0.0638 - val_loss: 0.6522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7894 - accuracy: 0.0638 - val_loss: 0.7058 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6937 - accuracy: 0.6809 - val_loss: 0.6824 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6992 - accuracy: 0.0851 - val_loss: 0.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6927 - accuracy: 0.1915 - val_loss: 0.6868 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6967 - accuracy: 0.1064 - val_loss: 0.6913 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6885 - accuracy: 0.2766 - val_loss: 0.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6891 - accuracy: 0.0851 - val_loss: 0.6708 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6955 - accuracy: 0.0638 - val_loss: 0.6787 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6900 - accuracy: 0.0638 - val_loss: 0.6671 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6939 - accuracy: 0.0000e+00\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6935 - accuracy: 0.5208 - val_loss: 0.6591 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6850 - accuracy: 0.0417 - val_loss: 0.8352 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7340 - accuracy: 0.7292 - val_loss: 0.6624 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6903 - accuracy: 0.0625 - val_loss: 0.6879 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6825 - accuracy: 0.2917 - val_loss: 0.6782 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6768 - accuracy: 0.2708 - val_loss: 0.6862 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6920 - accuracy: 0.2292 - val_loss: 0.6722 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6849 - accuracy: 0.2292 - val_loss: 0.7170 - val_accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6607 - accuracy: 0.5833 - val_loss: 0.6971 - val_accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6428 - accuracy: 0.5417 - val_loss: 0.6949 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6940 - accuracy: 0.6923\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6910 - accuracy: 0.0426 - val_loss: 0.6874 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6931 - accuracy: 0.0213 - val_loss: 0.6857 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6907 - accuracy: 0.0213 - val_loss: 0.6842 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6910 - accuracy: 0.0213 - val_loss: 0.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6910 - accuracy: 0.0213 - val_loss: 0.6815 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6920 - accuracy: 0.0213 - val_loss: 0.6803 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6884 - accuracy: 0.0213 - val_loss: 0.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.6906 - accuracy: 0.0213 - val_loss: 0.6781 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6910 - accuracy: 0.0213 - val_loss: 0.6771 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6875 - accuracy: 0.0213 - val_loss: 0.6761 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6926 - accuracy: 0.0741\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6953 - accuracy: 0.7021 - val_loss: 0.7025 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6936 - accuracy: 0.7021 - val_loss: 0.6999 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6964 - accuracy: 0.6596 - val_loss: 0.6972 - val_accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6960 - accuracy: 0.6383 - val_loss: 0.6944 - val_accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6916 - accuracy: 0.4681 - val_loss: 0.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6980 - accuracy: 0.1277 - val_loss: 0.6894 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6894 - accuracy: 0.1915 - val_loss: 0.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6930 - accuracy: 0.1277 - val_loss: 0.6850 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6903 - accuracy: 0.0638 - val_loss: 0.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6936 - accuracy: 0.0638 - val_loss: 0.6810 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6925 - accuracy: 0.0000e+00\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6952 - accuracy: 0.0417 - val_loss: 0.6835 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6902 - accuracy: 0.0417 - val_loss: 0.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6930 - accuracy: 0.0417 - val_loss: 0.6828 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6948 - accuracy: 0.0417 - val_loss: 0.6830 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6947 - accuracy: 0.0417 - val_loss: 0.6834 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6933 - accuracy: 0.0417 - val_loss: 0.6839 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6920 - accuracy: 0.0417 - val_loss: 0.6842 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6941 - accuracy: 0.0417 - val_loss: 0.6848 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6962 - accuracy: 0.0417 - val_loss: 0.6855 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6952 - accuracy: 0.0417 - val_loss: 0.6863 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6901 - accuracy: 0.0385\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6938 - accuracy: 0.2553 - val_loss: 0.6944 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6880 - accuracy: 0.5532 - val_loss: 0.6883 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6948 - accuracy: 0.2128 - val_loss: 0.6866 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6886 - accuracy: 0.1915 - val_loss: 0.6839 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6937 - accuracy: 0.0213 - val_loss: 0.6832 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7024 - accuracy: 0.0638 - val_loss: 0.6823 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6876 - accuracy: 0.1064 - val_loss: 0.6799 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6881 - accuracy: 0.0213 - val_loss: 0.6788 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6912 - accuracy: 0.0213 - val_loss: 0.6783 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6929 - accuracy: 0.0213 - val_loss: 0.6775 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6926 - accuracy: 0.0741\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 100, 32)           160000    \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,153\n",
      "Trainable params: 163,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Project Python\\SentimenAnalisis-OFA\\crawling.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project%20Python/SentimenAnalisis-OFA/crawling.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Project%20Python/SentimenAnalisis-OFA/crawling.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mfit(X_train_pad, y_train)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py:248\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape for y: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(y\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    247\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py:175\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m fit_args \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(Sequential\u001b[39m.\u001b[39mfit))\n\u001b[0;32m    173\u001b[0m fit_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 175\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:959\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    956\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    958\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    960\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    962\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    963\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[0;32m    964\u001b[0m           args, kwds))\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:142\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m--> 142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_concrete_function(\n\u001b[0;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m    299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 300\u001b[0m     func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    301\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name,\n\u001b[0;32m    302\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_function,\n\u001b[0;32m    303\u001b[0m         args,\n\u001b[0;32m    304\u001b[0m         kwargs,\n\u001b[0;32m    305\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39mfunc_graph,\n\u001b[0;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autograph,\n\u001b[0;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autograph_options,\n\u001b[0;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39marg_names,\n\u001b[0;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_capture_by_value,\n\u001b[0;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    313\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    664\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 667\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    668\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39mconverted_call(\n\u001b[0;32m   1190\u001b[0m       original_func,\n\u001b[0;32m   1191\u001b[0m       args,\n\u001b[0;32m   1192\u001b[0m       kwargs,\n\u001b[0;32m   1193\u001b[0m       options\u001b[39m=\u001b[39mautograph\u001b[39m.\u001b[39mConversionOptions(\n\u001b[0;32m   1194\u001b[0m           recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   1195\u001b[0m           optional_features\u001b[39m=\u001b[39mautograph_options,\n\u001b[0;32m   1196\u001b[0m           user_requested\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   1197\u001b[0m       ))\n\u001b[0;32m   1198\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1n1_r9ge.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1268\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1264\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1265\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m     )\n\u001b[0;32m   1267\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1268\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mrun(run_step, args\u001b[39m=\u001b[39m(data,))\n\u001b[0;32m   1269\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1270\u001b[0m     outputs,\n\u001b[0;32m   1271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1272\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1273\u001b[0m )\n\u001b[0;32m   1274\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1312\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1315\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extended\u001b[39m.\u001b[39mcall_for_each_replica(fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2893\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2894\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2895\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3694\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3695\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3696\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1249\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain_step(data)\n\u001b[0;32m   1250\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1054\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1053\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m-> 1054\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mminimize(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables, tape\u001b[39m=\u001b[39mtape)\n\u001b[0;32m   1055\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:585\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    555\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \n\u001b[0;32m    557\u001b[0m \u001b[39m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m \n\u001b[0;32m    584\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_gradients(\n\u001b[0;32m    586\u001b[0m         loss, var_list\u001b[39m=\u001b[39mvar_list, grad_loss\u001b[39m=\u001b[39mgrad_loss, tape\u001b[39m=\u001b[39mtape\n\u001b[0;32m    587\u001b[0m     )\n\u001b[0;32m    588\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:643\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    641\u001b[0m var_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(var_list)\n\u001b[0;32m    642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/gradients\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 643\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_gradients(\n\u001b[0;32m    644\u001b[0m         tape, loss, var_list, grad_loss\n\u001b[0;32m    645\u001b[0m     )\n\u001b[0;32m    647\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_valid_dtypes(\n\u001b[0;32m    648\u001b[0m     [\n\u001b[0;32m    649\u001b[0m         v\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    652\u001b[0m     ]\n\u001b[0;32m    653\u001b[0m )\n\u001b[0;32m    655\u001b[0m \u001b[39mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:519\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gradients\u001b[39m(\u001b[39mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, var_list, grad_loss)\n\u001b[0;32m    520\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1063\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1057\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1058\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1059\u001b[0m           output_gradients))\n\u001b[0;32m   1060\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1061\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1063\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39mimperative_grad(\n\u001b[0;32m   1064\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape,\n\u001b[0;32m   1065\u001b[0m     flat_targets,\n\u001b[0;32m   1066\u001b[0m     flat_sources,\n\u001b[0;32m   1067\u001b[0m     output_gradients\u001b[39m=\u001b[39moutput_gradients,\n\u001b[0;32m   1068\u001b[0m     sources_raw\u001b[39m=\u001b[39mflat_sources_raw,\n\u001b[0;32m   1069\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39munconnected_gradients)\n\u001b[0;32m   1071\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1072\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39mas_str(unconnected_gradients\u001b[39m.\u001b[39mvalue))\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:634\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._backward.<locals>._backward_function\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward_function\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m    633\u001b[0m   call_op \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mop\n\u001b[1;32m--> 634\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rewrite_forward_and_call_backward(call_op, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:550\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._rewrite_forward_and_call_backward\u001b[1;34m(self, op, *doutputs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rewrite_forward_and_call_backward\u001b[39m(\u001b[39mself\u001b[39m, op, \u001b[39m*\u001b[39mdoutputs):\n\u001b[0;32m    549\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 550\u001b[0m   forward_function, backwards_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_backward(\u001b[39mlen\u001b[39m(doutputs))\n\u001b[0;32m    551\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m backwards_function\u001b[39m.\u001b[39moutputs:\n\u001b[0;32m    552\u001b[0m     \u001b[39mreturn\u001b[39;00m backwards_function\u001b[39m.\u001b[39mstructured_outputs\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:483\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39mif\u001b[39;00m forward_backward \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    482\u001b[0m   \u001b[39mreturn\u001b[39;00m forward_backward\n\u001b[1;32m--> 483\u001b[0m forward, backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_forward_backward(num_doutputs)\n\u001b[0;32m    484\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_function_pairs[num_doutputs] \u001b[39m=\u001b[39m (forward, backward)\n\u001b[0;32m    485\u001b[0m \u001b[39mreturn\u001b[39;00m forward, backward\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:526\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m    524\u001b[0m   backwards_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mFuncGraph(\n\u001b[0;32m    525\u001b[0m       _backward_name(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mname))\n\u001b[1;32m--> 526\u001b[0m   func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    527\u001b[0m       name\u001b[39m=\u001b[39mbackwards_graph\u001b[39m.\u001b[39mname,\n\u001b[0;32m    528\u001b[0m       python_func\u001b[39m=\u001b[39m_backprop_function,\n\u001b[0;32m    529\u001b[0m       args\u001b[39m=\u001b[39m[], kwargs\u001b[39m=\u001b[39m{},\n\u001b[0;32m    530\u001b[0m       signature\u001b[39m=\u001b[39msignature,\n\u001b[0;32m    531\u001b[0m       func_graph\u001b[39m=\u001b[39mbackwards_graph)\n\u001b[0;32m    532\u001b[0m   backwards_graph_captures \u001b[39m=\u001b[39m backwards_graph\u001b[39m.\u001b[39mexternal_captures\n\u001b[0;32m    533\u001b[0m   captures_from_forward \u001b[39m=\u001b[39m [\n\u001b[0;32m    534\u001b[0m       c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m backwards_graph_captures \u001b[39mif\u001b[39;00m\n\u001b[0;32m    535\u001b[0m       \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(c, ops\u001b[39m.\u001b[39mEagerTensor) \u001b[39mand\u001b[39;00m c\u001b[39m.\u001b[39mgraph \u001b[39mis\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph]\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:517\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward.<locals>._backprop_function\u001b[1;34m(*grad_ys)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backprop_function\u001b[39m(\u001b[39m*\u001b[39mgrad_ys):\n\u001b[0;32m    516\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 517\u001b[0m     \u001b[39mreturn\u001b[39;00m gradients_util\u001b[39m.\u001b[39m_GradientsHelper(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    518\u001b[0m         trainable_outputs,\n\u001b[0;32m    519\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m         grad_ys\u001b[39m=\u001b[39mgrad_ys,\n\u001b[0;32m    521\u001b[0m         src_graph\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    696\u001b[0m                              \u001b[39mlambda\u001b[39;00m: grad_fn(op, \u001b[39m*\u001b[39mout_grads))\n\u001b[0;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:329\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    326\u001b[0m     xla_compile \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m xla_compile:\n\u001b[1;32m--> 329\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn()  \u001b[39m# Exit early\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m# together with the non-gradient computation.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[39mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 696\u001b[0m                              \u001b[39mlambda\u001b[39;00m: grad_fn(op, \u001b[39m*\u001b[39mout_grads))\n\u001b[0;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:448\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    445\u001b[0m   \u001b[39mreturn\u001b[39;00m counter \u001b[39m<\u001b[39m forward_loop_iters\n\u001b[0;32m    447\u001b[0m grad_cond_name \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39munique_grad_fn_name(op\u001b[39m.\u001b[39mget_attr(\u001b[39m\"\u001b[39m\u001b[39mcond\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mname)\n\u001b[1;32m--> 448\u001b[0m cond_grad_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    449\u001b[0m     grad_cond_name, grad_cond, loop_vars, {},\n\u001b[0;32m    450\u001b[0m     func_graph\u001b[39m=\u001b[39mutil\u001b[39m.\u001b[39mWhileCondFuncGraph(grad_cond_name))\n\u001b[0;32m    452\u001b[0m _check_num_inputs_outputs(cond_grad_graph, body_grad_graph, \u001b[39mlen\u001b[39m(loop_vars))\n\u001b[0;32m    454\u001b[0m outputs \u001b[39m=\u001b[39m _build_while_op(\n\u001b[0;32m    455\u001b[0m     loop_vars,\n\u001b[0;32m    456\u001b[0m     cond_grad_graph,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     num_original_outputs\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(body_grad_graph\u001b[39m.\u001b[39moutputs),\n\u001b[0;32m    462\u001b[0m     stateful_parallelism\u001b[39m=\u001b[39mstateful_parallelism)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1123\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1120\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   1122\u001b[0m \u001b[39mif\u001b[39;00m create_placeholders:\n\u001b[1;32m-> 1123\u001b[0m   func_args, func_kwargs \u001b[39m=\u001b[39m _create_placeholders(args, kwargs, arg_names)\n\u001b[0;32m   1124\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1125\u001b[0m   func_args, func_kwargs \u001b[39m=\u001b[39m args, kwargs\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1423\u001b[0m, in \u001b[0;36m_create_placeholders\u001b[1;34m(args, kwargs, arg_names)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[39mfor\u001b[39;00m name, trace_type_arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(arg_names, arg_trace_types\u001b[39m.\u001b[39mcomponents):\n\u001b[0;32m   1422\u001b[0m   placeholder_context\u001b[39m.\u001b[39mupdate_naming_scope(name)\n\u001b[1;32m-> 1423\u001b[0m   placeholder \u001b[39m=\u001b[39m trace_type_arg\u001b[39m.\u001b[39mplaceholder_value(placeholder_context)\n\u001b[0;32m   1424\u001b[0m   func_args\u001b[39m.\u001b[39mappend(placeholder)\n\u001b[0;32m   1426\u001b[0m func_kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py:227\u001b[0m, in \u001b[0;36mTensorSpec.placeholder_value\u001b[1;34m(self, placeholder_context)\u001b[0m\n\u001b[0;32m    225\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39mor\u001b[39;00m placeholder_context\u001b[39m.\u001b[39mnaming_scope\n\u001b[0;32m    226\u001b[0m context_graph \u001b[39m=\u001b[39m placeholder_context\u001b[39m.\u001b[39mcontext_graph\n\u001b[1;32m--> 227\u001b[0m placeholder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_placeholder(context_graph, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    228\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m   \u001b[39m# Record the requested/user-specified name in case it's different than\u001b[39;00m\n\u001b[0;32m    230\u001b[0m   \u001b[39m# the uniquified name, for validation when exporting signatures.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m   placeholder\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39m_set_attr(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    232\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m_user_specified_name\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    233\u001b[0m       attr_value_pb2\u001b[39m.\u001b[39mAttrValue(s\u001b[39m=\u001b[39mcompat\u001b[39m.\u001b[39mas_bytes(name)))\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py:255\u001b[0m, in \u001b[0;36mTensorSpec._graph_placeholder\u001b[1;34m(self, graph, name)\u001b[0m\n\u001b[0;32m    253\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m: shape}\n\u001b[0;32m    254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m   op \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    256\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mPlaceholder\u001b[39m\u001b[39m\"\u001b[39m, [], [dtype], input_types\u001b[39m=\u001b[39m[],\n\u001b[0;32m    257\u001b[0m       attrs\u001b[39m=\u001b[39mattrs, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    258\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    259\u001b[0m   \u001b[39m# TODO(b/262413656) Sometimes parameter names are not valid op names, in\u001b[39;00m\n\u001b[0;32m    260\u001b[0m   \u001b[39m# which case an unnamed placeholder is created instead. Update this logic\u001b[39;00m\n\u001b[0;32m    261\u001b[0m   \u001b[39m# to sanitize the name instead of falling back on unnamed placeholders.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m   logging\u001b[39m.\u001b[39mwarning(e)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:707\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    705\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    706\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 707\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    708\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    709\u001b[0m     compute_device)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3814\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3814\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3815\u001b[0m       node_def,\n\u001b[0;32m   3816\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[0;32m   3817\u001b[0m       inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m   3818\u001b[0m       output_types\u001b[39m=\u001b[39mdtypes,\n\u001b[0;32m   3819\u001b[0m       control_inputs\u001b[39m=\u001b[39mcontrol_inputs,\n\u001b[0;32m   3820\u001b[0m       input_types\u001b[39m=\u001b[39minput_types,\n\u001b[0;32m   3821\u001b[0m       original_op\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_original_op,\n\u001b[0;32m   3822\u001b[0m       op_def\u001b[39m=\u001b[39mop_def)\n\u001b[0;32m   3823\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3824\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2112\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2109\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2111\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2112\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39mop_def)\n\u001b[0;32m   2113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\AppData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1943\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1942\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 1943\u001b[0m   op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_NewOperation(c_graph,\n\u001b[0;32m   1944\u001b[0m                                               compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mop),\n\u001b[0;32m   1945\u001b[0m                                               compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname))\n\u001b[0;32m   1946\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1947\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train_pad, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan hasil terbaik\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat model dengan hyperparameter terbaik yang telah ditentukan\n",
    "best_params = grid_result.best_params_\n",
    "model = KerasClassifier(build_fn=create_model, **best_params)\n",
    "\n",
    "model_prediction = model.fit(X_train_pad, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melanjutkan eksekusi kode setelah pencarian hiperparameter\n",
    "\n",
    "# Evaluasi model\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi pada data uji\n",
    "predictions = model.predict(X_test_pad)\n",
    "\n",
    "# Konversi nilai probabilitas menjadi kelas\n",
    "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "\n",
    "# Evaluasi klasifikasi\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predicted_labels))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
